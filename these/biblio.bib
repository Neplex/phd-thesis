@inproceedings{abiteboulMiseajourBasesDonnees1985,
  title = {Mise-\`a-Jour Des {{Bases}} de {{Donn\'ees}} Contenant de l'information Incompl\`ete},
  booktitle = {Journ\'ees Bases de Donn\'ees Avanc\'es, 6-8 Mars 1985, St. {{Pierre}} de Chartreuse (Informal Proceedings).},
  author = {Abiteboul, Serge and Grahne, G{\"o}sta},
  year = {1985},
  optbibsource = {dblp computer science bibliography, http://dblp.org},
  optbiburl = {http://dblp.org/rec/bib/conf/bda/AbiteboulG85},
  optcrossref = {DBLP:conf/bda/1985},
  opttimestamp = {Tue, 31 Oct 2006 14:01:45 +0100},
  keywords = {\#nosource,â›” No DOI found}
}

@article{ahoEfficientOptimizationClass1979,
  ids = {ASU79,ahoEfficientOptimizationClass1979a},
  title = {Efficient Optimization of a Class of Relational Expressions},
  author = {Aho, Alfred V. and Sagiv, Yehoshua and Ullman, Jeffrey D.},
  year = {1979},
  journal = {ACM Transactions on Database Systems (TODS)},
  volume = {4},
  number = {4},
  pages = {435--454},
  publisher = {{ACM New York, NY, USA}},
  issn = {0362-5915},
  doi = {10.1145/320107.320112},
  abstract = {The design of several database query languages has been influenced by Codd's relational algebra. This paper discusses the difficulty of optimizing queries based on the relational algebra operations select, project, and join. A matrix, called a tableau, is proposed as a useful device for representing the value of a query, and optimization of queries is couched in terms of finding a minimal tableau equivalent to a given one. Functional dependencies can be used to imply additional equivalences among tableaux. Although the optimization problem is NP-complete, a polynomial time algorithm exists to optimize tableaux that correspond to an important subclass of queries.},
  optbibsource = {dblp computer science bibliography, https://dblp.org},
  optbiburl = {https://dblp.org/rec/journals/tods/AhoSU79.bib},
  optdoi = {10.1145/320107.320112},
  opttimestamp = {Tue, 06 Nov 2018 12:51:47 +0100},
  opturl = {https://doi.org/10.1145/320107.320112},
  keywords = {equivalence of queries,NP-completeness,query optimization,relational algebra,relational database,tableaux},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\2SKKF3ZD\\Aho et al. - 1979 - Efficient optimization of a class of relational ex.pdf}
}

@article{alvesUpdateRulesDatalog1998,
  ids = {HLS98},
  title = {Update {{Rules}} in {{Datalog Programs}}},
  author = {ALVES, M{\'i}RIAN HALFELD FERRARI and LAURENT, {\relax DOMINIQUE} and SPYRATOS, {\relax NICOLS}},
  year = {1998},
  month = dec,
  journal = {Journal of Logic and Computation},
  volume = {8},
  number = {6},
  pages = {745--775},
  publisher = {{OUP}},
  issn = {1465-363X},
  doi = {10.1093/logcom/8.6.745},
  abstract = {We propose a deductive database model containing two kinds of rules: update rules of the form L0{$\leftarrow$}L1, where L0 and L1 are literals, and query rules of the form of normal logic program rules. A basic feature of our approach is that new knowledge inputs are always assimilated. Moreover, updates are always deterministic and they preserve database consistency.We consider that update rules have higher priority than query rules, i.e., update rules may generate exceptions to query-driven derivations. We introduce a semantics framework for database update and query answering, based on the well-founded semantics. We also suggest an alternative approach based on extended logic programs and we show that our database model can be defined in terms of non-monotonic formalisms.},
  optbibsource = {dblp computer science bibliography, http://dblp.org},
  optbiburl = {http://dblp.uni-trier.de/rec/bib/journals/logcom/AlvesLS98},
  optdoi = {10.1093/logcom/8.6.745},
  opttimestamp = {Wed, 29 Jun 2011 15:52:37 +0200},
  opturl = {http://dx.doi.org/10.1093/logcom/8.6.745},
  keywords = {\#nosource,Datalog,deductive database,update},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\7CB956IH\\8142245.html;C\:\\Users\\nhiot\\Zotero\\storage\\B72S7SY9\\8142245.html}
}

@inproceedings{amaviNaturalLanguageQuerying2020,
  title = {Natural {{Language Querying System Through Entity Enrichment}}},
  booktitle = {{{ADBIS}}, {{TPDL}} and {{EDA}} 2020 {{Common Workshops}} and {{Doctoral Consortium}}: {{International Workshops}}: {{DOING}}, {{MADEISD}}, {{SKG}}, {{BBIGAP}}, {{SIMPDA}}, {{AIMinScience}} 2020 and {{Doctoral Consortium}}, {{Lyon}}, {{France}}, {{August}} 25\textendash 27, 2020, {{Proceedings}} 24},
  author = {Amavi, Joshua and Halfeld Ferrari, Mirian and Hiot, Nicolas},
  editor = {Bellatreche, Ladjel and Bielikov{\'a}, M{\'a}ria and Boussa{\"i}d, Omar and Catania, Barbara and Darmont, J{\'e}r{\^o}me and Demidova, Elena and Duchateau, Fabien and Hall, Mark and Mer{\v c}un, Tanja and Novikov, Boris and Papatheodorou, Christos and Risse, Thomas and Romero, Oscar and Sautot, Lucile and Talens, Guilaine and Wrembel, Robert and {\v Z}umer, Maja},
  year = {2020},
  month = aug,
  series = {Communications in {{Computer}} and {{Information Science}}},
  volume = {1260},
  pages = {36--48},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10/gg8642},
  abstract = {This paper focuses on a domain expert querying system over databases. It presents a solution designed for a French enterprise interested in offering a natural language interface for its clients. The approach, based on entity enrichment, aims at translating natural language queries into database queries. In this paper, the database is treated through a logical paradigm, suggesting the adaptability of our approach to different database models. The good precision of our method is shown through some preliminary experiments.},
  copyright = {All rights reserved},
  hal_id = {hal-02959502},
  hal_version = {v1},
  isbn = {978-3-030-55814-7},
  langid = {english},
  keywords = {\#nosource,Database query,me,NLI,NLP,Question answering},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\FIIBATP8\\Amavi et al. - 2020 - Natural Language Querying System Through Entity En.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\XGTK6R7N\\DOING13.mp4;C\:\\Users\\nhiot\\Zotero\\storage\\MT5B2A5X\\978-3-030-55814-7_3.html}
}

@inproceedings{anglesPGKeysKeysProperty2021,
  ids = {anglesPgkeysKeysProperty2021},
  title = {{{PG-Keys}}: {{Keys}} for Property Graphs},
  shorttitle = {Pg-Keys},
  booktitle = {Proceedings of the 2021 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Angles, Renzo and Bonifati, Angela and Dumbrava, Stefania and Fletcher, George and Hare, Keith W. and Hidders, Jan and Lee, Victor E. and Li, Bei and Libkin, Leonid and Martens, Wim and Murlak, Filip and Perryman, Josh and Savkovic, Ognjen and Schmidt, Michael and Sequeda, Juan F. and Staworko, Slawek and Tomaszuk, Dominik},
  year = {2021},
  pages = {2423--2436},
  publisher = {{ACM}},
  doi = {10.1145/3448016.3457561},
  keywords = {\#nosource},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\FMUARDIF\\Angles et al. - 2021 - PG-Keys Keys for property graphs.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\7YULBJER\\3448016.html}
}

@book{bonifatiQueryingGraphs2018,
  ids = {BFVY2018},
  title = {Querying Graphs},
  author = {Bonifati, Angela and Fletcher, George and Voigt, Hannes and Yakovets, Nikolay and Jagadish, H. V.},
  year = {2018},
  series = {Synthesis Lectures on Data Management},
  volume = {10},
  publisher = {{Morgan \& Claypool Publishers}},
  optbibsource = {dblp computer science bibliography, https://dblp.org},
  optbiburl = {https://dblp.org/rec/series/synthesis/2018Bonifati.bib},
  optdoi = {10.2200/S00873ED1V01Y201808DTM051},
  opttimestamp = {Mon, 15 Nov 2021 16:15:59 +0100},
  opturl = {https://doi.org/10.2200/S00873ED1V01Y201808DTM051},
  keywords = {\#nosource},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\ZTHHVBZS\\Bonifati et al. - 2018 - Querying graphs.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\9CCKMBG8\\978-3-031-01864-0.html}
}

@article{chabinConsistentUpdatingDatabases2020,
  ids = {CHL19,CHL20,ConsistentUpdatingDatabase,chabinConsistentUpdatingDatabase,chabinConsistentUpdatingDatabases2019,chabinConsistentUpdatingDatabases2019b,chabinConsistentUpdatingDatabases2020a,chabinConsistentUpdatingDatabases2020b,ferrariConsistentUpdatingDatabases2020},
  title = {Consistent {{Updating}} of {{Databases}} with {{Marked Nulls}}},
  author = {Chabin, Jacques and {Halfeld-Ferrari}, Mirian and Laurent, Dominique},
  year = {2020},
  month = apr,
  journal = {Knowledge and Information Systems (KAIS)},
  volume = {62},
  number = {4},
  pages = {1571--1609},
  publisher = {{Springer}},
  issn = {0219-3116},
  doi = {10.1007/s10115-019-01402-w},
  urldate = {2023-07-05},
  abstract = {This paper revisits the problem of consistency maintenance when insertions or deletions are performed on a valid database containing marked nulls. This problem comes back to light in real-world linked data or RDF databases when blank nodes are associated with null values. This paper proposes solutions for the main problems one has to face when dealing with updates and constraints, namely update determinism, minimal change and leanness of an RDF graph instance. The update semantics is formally introduced and the notion of core is used to ensure a database as small as possible (i.e.~~ the RDF graph leanness). Our algorithms allow the use of constraints such as tuple-generating dependencies, offering a way for solving many practical problems.},
  langid = {english},
  optbibsource = {dblp computer science bibliography, https://dblp.org},
  optbiburl = {https://dblp.org/rec/journals/kais/ChabinFL20.bib},
  optdoi = {10.1007/s10115-019-01402-w},
  opttimestamp = {Mon, 04 May 2020 13:22:49 +0200},
  opturl = {https://doi.org/10.1007/s10115-019-01402-w},
  keywords = {\#nosource,Constraints,Logical database,Null values,RDF,TGD,Updates},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\ZZP3MJCM\\Chabin et al. - 2020 - Consistent Updating of Databases with Marked Nulls.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\4YE6ECDH\\s10115-019-01402-w.html}
}

@inproceedings{chabinContextdrivenQueryingSystem2018,
  title = {A {{Context-driven Querying System}} for {{Urban Graph Analysis}}},
  booktitle = {Proceedings of the 22nd {{International Database Engineering}} \& {{Applications Symposium}}},
  author = {Chabin, Jacques and {Gomes-Jr.}, Luiz and {Halfeld-Ferrari}, Mirian},
  year = {2018},
  series = {{{IDEAS}} 2018},
  pages = {297--301},
  publisher = {{ACM Press}},
  address = {{Villa San Giovanni, Italy}},
  doi = {10/gfvn2w},
  urldate = {2018-12-29},
  abstract = {This paper presents a context-driven query system for urban computing where users are responsible for defining their own restrictions over which datalog-like queries are built. Instead of imposing constraints on databases, our goal is to filter consistent data during the query process. Our query language is able to express aggregates in recursive rules, allowing it to capture network properties typical of graph analysis. This paper presents our query system and analyzes its capabilities using use cases in Urban Computing.},
  isbn = {978-1-4503-6527-7},
  langid = {english},
  keywords = {constraints,data graph,data quality,Query language,smart city},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\BQTKFT9V\\Chabin et al. - 2018 - A Context-driven Querying System for Urban Graph A.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\MGXJHLF7\\citation.html;C\:\\Users\\nhiot\\Zotero\\storage\\QEF3INHL\\hal-01837921.html}
}

@inproceedings{chabinGraphRewritingRules2020,
  ids = {chabinGraphRewritingRules2020a},
  title = {Graph {{Rewriting Rules}} for {{RDF Database Evolution Management}}},
  booktitle = {Proceedings of the 22nd {{International Conference}} on {{Information Integration}} and {{Web-based Applications}} \& {{Services}}},
  author = {Chabin, Jacques and Eichler, C{\'e}dric and {Halfeld-Ferrari}, Mirian and Hiot, Nicolas},
  year = {2020},
  month = nov,
  series = {{{iiWAS}} '20},
  pages = {134--143},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3428757.3429126},
  urldate = {2022-05-13},
  abstract = {This paper introduces SetUp, a theoretical and applied framework for the management of RDF/S database evolution on the basis of graph rewriting rules. Rewriting rules formalize instance or schema changes, ensuring graph's consistency with respect to given constraints. Constraints considered in this paper are a well known variant of RDF/S semantic, but the approach can be adapted to user-defined constraints. Furthermore, SetUp manages updates by ensuring rule applicability through the generation of side-effects: new updates which guarantee that rule application conditions hold. We provide herein formal validation and experimental evaluation of SetUp.},
  isbn = {978-1-4503-8922-8},
  keywords = {Constraints,Database Management,Graph rewriting,me,Update},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\98WY6YI9\\Chabin et al. - 2020 - Graph Rewriting Rules for RDF Database Evolution M.pdf}
}

@article{chabinGraphRewritingRules2021,
  ids = {chabinGraphRewritingRules2021a,chabinGraphRewritingRules2021b},
  title = {Graph Rewriting Rules for {{RDF}} Database Evolution: Optimizing Side-Effect Processing},
  shorttitle = {Graph Rewriting Rules for {{RDF}} Database Evolution},
  author = {Chabin, Jacques and Eichler, C{\'e}dric and Ferrari, Mirian Halfeld and Hiot, Nicolas},
  year = {2021},
  month = aug,
  journal = {International Journal of Web Information Systems},
  volume = {17},
  number = {6},
  pages = {622--644},
  publisher = {{Emerald Publishing Limited}},
  doi = {10.1108/IJWIS-03-2021-0033},
  keywords = {me},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\GNKTXUMA\\html.html;C\:\\Users\\nhiot\\Zotero\\storage\\UP65BUJK\\hal-03329965v1.html}
}

@techreport{chabinGraphRewritingSystem2020,
  type = {Research {{Report}}},
  ids = {chabinGraphRewritingSystem2020b,rewritingRules},
  title = {Graph {{Rewriting System}} for {{Consistent Evolution}} of {{RDF}}/{{S}} Databases},
  author = {Chabin, Jacques and Eichler, C{\'e}dric and {Halfeld-Ferrari}, Mirian and Hiot, Nicolas},
  year = {2020},
  institution = {{LIFO, Universit\'e d'Orl\'eans, INSA Centre Val de Loire}},
  urldate = {2023-08-03},
  abstract = {This paper investigates the use of graph rewriting rules to model updates-instance or schema changes-on RDF/S databases which are expected to satisfy RDF intrinsic semantic constraints. Such databases being modeled as knowledge graphs, we propose graph rewriting rules formalizing atomic updates whose application transforms the graph and necessarily preserves its consistency. If an update has to be applied when the application conditions of the corresponding rule do not hold, side-effects are generated: they engender new updates in order to ensure the rule applicability. Our system, SetUp, implements our updating approach for RDF/S data and offers a theoretical and applied framework for ensuring consistency when a RDF knowledge graph evolves.},
  copyright = {All rights reserved},
  keywords = {me},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\9GMCC3QH\\Chabin et al. - 2020 - Graph Rewriting System for Consistent Evolution of.pdf}
}

@article{chabinIncrementalConsistentUpdating2023,
  title = {Incremental {{Consistent Updating}} of {{Incomplete Databases}}},
  author = {Chabin, Jacques and Ferrari, Mirian Halfeld and Hiot, Nicolas and Laurent, Dominique},
  year = {2023},
  journal = {arXiv preprint arXiv:2302.06246},
  eprint = {2302.06246},
  archiveprefix = {arxiv},
  keywords = {\#nosource,â›” No DOI found,me}
}

@techreport{chabinSpecificationSideeffectManagement2020,
  type = {{{PhD Thesis}}},
  title = {Specification of Side-Effect Management Techniques for Semantic Graph Sanitization},
  author = {Chabin, Jacques and Eichler, C{\'e}dric and {Halfeld-Ferrari}, Mirian and Hiot, Nicolas},
  year = {2020},
  institution = {{LIFO, Universit\'e d'Orl\'eans, INSA Centre Val de Loire}},
  keywords = {\#nosource,me}
}

@unpublished{chabinUsingGraphGrammar2019,
  title = {Using a Graph Grammar to Update a {{RDF}}/{{S}} Document},
  author = {Chabin, Jacques and Eichler, C{\'e}dric and Halfeld Ferrari, Mirian},
  year = {2019},
  langid = {english},
  keywords = {\#nosource}
}

@inproceedings{chandraOptimalImplementationConjunctive1977,
  ids = {CM77,chandraOptimalImplementationConjunctive1977a},
  title = {Optimal Implementation of Conjunctive Queries in Relational Data Bases},
  booktitle = {Proceedings of the Ninth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Chandra, Ashok K. and Merlin, Philip M.},
  year = {1977},
  month = may,
  series = {{{STOC}} '77},
  pages = {77--90},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/800105.803397},
  abstract = {We define the class of conjunctive queries in relational data bases, and the generalized join operator on relations. The generalized join plays an important part in answering conjunctive queries, and it can be implemented using matrix multiplication. It is shown that while answering conjunctive queries is NP complete (general queries are PSPACE complete), one can find an implementation that is within a constant of optimal. The main lemma used to show this is that each conjunctive query has a unique minimal equivalent query (much like minimal finite automata).},
  isbn = {978-1-4503-7409-5},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\JWTIK2V2\\Chandra et Merlin - 1977 - Optimal implementation of conjunctive queries in r.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\6D3X624J\\800105.html}
}

@inproceedings{consoleCopingIncompleteData2020,
  ids = {CGLT20},
  title = {Coping with {{Incomplete Data}}: {{Recent Advances}}},
  shorttitle = {Coping with {{Incomplete Data}}},
  booktitle = {Proceedings of the 39th {{ACM SIGMOD-SIGACT-SIGAI Symposium}} on {{Principles}} of {{Database Systems}}},
  author = {Console, Marco and Guagliardo, Paolo and Libkin, Leonid and Toussaint, Etienne},
  year = {2020},
  month = jun,
  series = {{{PODS}}'20},
  pages = {33--47},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3375395.3387970},
  urldate = {2023-08-03},
  abstract = {Handling incomplete data in a correct manner is a notoriously hard problem in databases. Theoretical approaches rely on the computationally hard notion of certain answers, while practical solutions rely on ad hoc query evaluation techniques based on three-valued logic. Can we find a middle ground, and produce correct answers efficiently? The paper surveys results of the last few years motivated by this question. We re-examine the notion of certainty itself, and show that it is much more varied than previously thought. We identify cases when certain answers can be computed efficiently and, short of that, provide deterministic and probabilistic approximation schemes for them. We look at the role of three-valued logic as used in SQL query evaluation, and discuss the correctness of the choice, as well as the necessity of such a logic for producing query answers.},
  isbn = {978-1-4503-7108-7},
  keywords = {\#nosource,approximate query answering,certain answers,incomplete information,many-valued logics,naive evaluation,relational databases},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\WHPR3IS7\\Console et al. - 2020 - Coping with Incomplete Data Recent Advances.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\KJF3RWAC\\3375395.html}
}

@article{cowieInformationExtraction2000,
  title = {Information Extraction},
  author = {Cowie, Jim and Wilks, Yorick},
  year = {2000},
  journal = {Handbook of Natural Language Processing},
  volume = {56},
  pages = {57},
  keywords = {â›” No DOI found},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\4Y7VTHGY\\Cowie et Wilks - 2000 - Information extraction.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\43IETTRD\\books.html}
}

@inproceedings{faginSemanticsUpdatesDatabases1983,
  ids = {FUV83},
  title = {On the Semantics of Updates in Databases},
  booktitle = {Proceedings of the 2nd {{ACM SIGACT-SIGMOD Symposium}} on {{Principles}} of {{Database Systems}}},
  author = {Fagin, Ronald and Ullman, Jeffrey D. and Vardi, Moshe Y.},
  year = {1983},
  month = mar,
  series = {{{PODS}} '83},
  pages = {352--365},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/588058.588100},
  urldate = {2023-08-03},
  abstract = {We suggest here a methodology for updating databases with integrity constraints and rules for deriving inexphcit information. First we consider the problem of updating arbitrary theories by inserting into them or deleting from them arbitrary sentences. The solution involves two key ideas when replacing an old theory by a new one we wish to minimize the change in the theory, and when there are several theories that involve minimal changes, we look for a new theory that reflects that ambiguity. The methodology is also adapted to updating databases, where different facts can carry different priorities, and to updating user views.},
  isbn = {978-0-89791-097-2},
  optbibsource = {dblp computer science bibliography, http://dblp.org},
  optbiburl = {http://dblp.org/rec/bib/conf/pods/FaginUV83},
  optcrossref = {DBLP:conf/pods/83},
  optdoi = {10.1145/588058.588100},
  opttimestamp = {Wed, 29 Mar 2017 16:45:25 +0200},
  opturl = {http://doi.acm.org/10.1145/588058.588100},
  keywords = {\#nosource},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\7NHGP5T8\\Fagin et al. - 1983 - On the semantics of updates in databases.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\7SGAML5K\\588058.html}
}

@article{faginUpdatingLogicalDatabases1986,
  ids = {FKUV86},
  title = {Updating Logical Databases},
  author = {Fagin, Ronald and Kuper, Gabriel M. and Ullman, Jeffrey D. and Vardi, Moshe Y.},
  year = {1986},
  journal = {Advances in Computing Research},
  volume = {3},
  pages = {1--18},
  optbibsource = {dblp computer science bibliography, http://dblp.org},
  optbiburl = {http://dblp.org/rec/bib/journals/acr/FaginKUV86},
  opttimestamp = {Thu, 03 Jan 2002 12:12:04 +0100},
  keywords = {\#nosource,â›” No DOI found},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\D2WVHHQN\\Fagin et al. - 1986 - Updating logical databases.pdf}
}

@article{fanDependenciesGraphs2019,
  ids = {fanDependenciesGraphs2019a},
  title = {Dependencies for {{Graphs}}},
  author = {Fan, Wenfei and Lu, Ping},
  year = {2019},
  month = feb,
  journal = {ACM Transactions on Database Systems (TODS)},
  volume = {44},
  number = {2},
  pages = {1--40},
  publisher = {{ACM New York, NY, USA}},
  issn = {0362-5915},
  doi = {10.1145/3287285},
  urldate = {2023-08-03},
  abstract = {This article proposes a class of dependencies for graphs, referred to as graph entity dependencies (GEDs). A GED is defined as a combination of a graph pattern and an attribute dependency. In a uniform format, GEDs can express graph functional dependencies with constant literals to catch inconsistencies, and keys carrying id literals to identify entities (vertices) in a graph. We revise the chase for GEDs and prove its Church-Rosser property. We characterize GED satisfiability and implication, and establish the complexity of these problems and the validation problem for GEDs, in the presence and absence of constant literals and id literals. We also develop a sound, complete and independent axiom system for finite implication of GEDs. In addition, we extend GEDs with built-in predicates or disjunctions, to strike a balance between the expressive power and complexity. We settle the complexity of the satisfiability, implication, and validation problems for these extensions.},
  keywords = {axiom system,built-in predicates,conditional functional dependencies,disjunction,EGDs,Graph dependencies,implication,keys,satisfiability,TGDs,validation},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\42IFQCS2\\3287285.html;C\:\\Users\\nhiot\\Zotero\\storage\\ULM587AG\\3287285.html}
}

@article{fanKeysGraphs2015,
  title = {Keys for Graphs},
  author = {Fan, Wenfei and Fan, Zhe and Tian, Chao and Dong, Xin Luna},
  year = {2015},
  month = aug,
  journal = {Proceedings of the VLDB Endowment},
  volume = {8},
  number = {12},
  pages = {1590--1601},
  publisher = {{VLDB Endowment}},
  issn = {2150-8097},
  doi = {10.14778/2824032.2824056},
  urldate = {2023-08-03},
  abstract = {Keys for graphs aim to uniquely identify entities represented by vertices in a graph. We propose a class of keys that are recursively defined in terms of graph patterns, and are interpreted with subgraph isomorphism. Extending conventional keys for relations and XML, these keys find applications in object identification, knowledge fusion and social network reconciliation. As an application, we study the entity matching problem that, given a graph G and a set {$\Sigma$} of keys, is to find all pairs of entities (vertices) in G that are identified by keys in {$\Sigma$}. We show that the problem is intractable, and cannot be parallelized in logarithmic rounds. Nonetheless, we provide two parallel scalable algorithms for entity matching, in MapReduce and a vertex-centric asynchronous model. Using real-life and synthetic data, we experimentally verify the effectiveness and scalability of the algorithms.},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\BZI62NTT\\Fan et al. - 2015 - Keys for graphs.pdf}
}

@article{flourisFormalFoundationsRDF2013,
  ids = {FKAC13},
  title = {Formal Foundations for {{RDF}}/{{S KB}} Evolution},
  author = {Flouris, Giorgos and Konstantinidis, George and Antoniou, Grigoris and Christophides, Vassilis},
  year = {2013},
  month = apr,
  journal = {Knowledge and Information Systems},
  volume = {35},
  number = {1},
  pages = {153--191},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-012-0500-2},
  urldate = {2019-06-20},
  langid = {english},
  optbibsource = {dblp computer science bibliography, http://dblp.org},
  optbiburl = {http://dblp.uni-trier.de/rec/bib/journals/kais/FlourisKAC13},
  optdoi = {10.1007/s10115-012-0500-2},
  opttimestamp = {Tue, 09 Apr 2013 17:54:05 +0200},
  opturl = {http://dx.doi.org/10.1007/s10115-012-0500-2},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\HGGAA4CM\\Flouris et al. - 2013 - Formal foundations for RDFS KB evolution.pdf}
}

@inproceedings{goasdoueEfficientQueryAnswering2013,
  ids = {GMR13,goasdoueEfficientQueryAnswering2013a},
  title = {Efficient Query Answering against Dynamic {{RDF}} Databases},
  booktitle = {Proceedings of the 16th {{International Conference}} on {{Extending Database Technology}}},
  author = {Goasdou{\'e}, Fran{\c c}ois and Manolescu, Ioana and Roati{\c s}, Alexandra},
  year = {2013},
  month = mar,
  series = {{{EDBT}} '13},
  pages = {299--310},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2452376.2452412},
  urldate = {2023-08-03},
  abstract = {A promising method for efficiently querying RDF data consists of translating SPARQL queries into efficient RDBMS-style operations. However, answering SPARQL queries requires handling RDF reasoning, which must be implemented outside the relational engines that do not support it. We introduce the database (DB) fragment of RDF, going beyond the expressive power of previously studied RDF fragments. We devise novel sound and complete techniques for answering Basic Graph Pattern (BGP) queries within the DB fragment of RDF, exploring the two established approaches for handling RDF semantics, namely reformulation and saturation. In particular, we focus on handling database updates within each approach and propose a method for incrementally maintaining the saturation; updates raise specific difficulties due to the rich RDF semantics. Our techniques are designed to be deployed on top of any RDBMS(-style) engine, and we experimentally study their performance trade-offs.},
  isbn = {978-1-4503-1597-5},
  keywords = {query answering,RDF fragments,reasoning},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\RV9HFH5N\\GoasdouÃ© et al. - 2013 - Efficient query answering against dynamic RDF data.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\ZEREIB62\\2452376.html}
}

@book{grahneProblemIncompleteInformation1991,
  ids = {Gra91},
  title = {The Problem of Incomplete Information in Relational Databases},
  author = {Grahne, G{\"o}sta},
  year = {1991},
  series = {Lecture Notes in Computer Science},
  volume = {554},
  publisher = {{Springer}},
  optbiburl = {http://dblp.org/rec/bib/books/sp/Grahne91},
  optdoi = {10.1007/3-540-54919-6},
  optisbn = {3-540-54919-6},
  optoptbibsource = {dblp computer science bibliography, http://dblp.org},
  opttimestamp = {Tue, 16 May 2017 14:01:46 +0200},
  opturl = {https://doi.org/10.1007/3-540-54919-6},
  keywords = {\#nosource},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\R23IRBKN\\3-540-54919-6_10.html}
}

@inproceedings{grishmanInformationExtractionTechniques1997,
  title = {Information Extraction: {{Techniques}} and Challenges},
  shorttitle = {Information Extraction},
  booktitle = {International Summer School on Information Extraction},
  author = {Grishman, Ralph},
  year = {1997},
  volume = {1299},
  pages = {10--27},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10/c998rq},
  isbn = {978-3-540-63438-6 978-3-540-69548-6},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\3TCL6VGD\\Grishman - 1997 - Information extraction Techniques and challenges.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\PYHSUCCK\\10.html}
}

@inproceedings{halfeld-ferrariRDFUpdatesConstraints2017,
  ids = {HHU17,halfeld-ferrariRDFUpdatesConstraints2017a},
  title = {{{RDF Updates}} with {{Constraints}}},
  booktitle = {Knowledge {{Engineering}} and {{Semantic Web}} - 8th {{International Conference}}, {{KESW}}, {{Szczecin}}, {{Poland}}, {{Proceedings}}},
  author = {{Halfeld-Ferrari}, Mirian and Hara, Carmem S. and Uber, Flavio R.},
  editor = {R{\'o}{\.z}ewski, Przemys{\l}aw and Lange, Christoph},
  year = {2017},
  series = {Communications in {{Computer}} and {{Information Science}}},
  volume = {786},
  pages = {229--245},
  publisher = {{Springer International Publishing}},
  address = {{Szczecin, Poland}},
  doi = {10/gf4bcm},
  abstract = {This paper deals with the problem of updating an RDF database, expected to satisfy user-defined constraints as well as RDF intrinsic semantic constraints. As updates may violate these constraints, side-effects are generated in order to preserve consistency. We investigate the use of nulls (blank nodes) as placeholders for unknown required data as a technique to provide this consistency and to reduce the number of side-effects. Experimental results validate our goals.},
  isbn = {978-3-319-69547-1 978-3-319-69548-8},
  langid = {english},
  optbibsource = {dblp computer science bibliography, https://dblp.org},
  optbiburl = {https://dblp.org/rec/bib/conf/kesw/FerrariHU17},
  optcrossref = {DBLP:conf/kesw/2017},
  optdoi = {10.1007/978-3-319-69548-8{$_1$}6},
  opttimestamp = {Tue, 09 Jan 2018 07:58:14 +0100},
  opturl = {https://doi.org/10.1007/978-3-319-69548-8{$_1$}6},
  keywords = {Constraints,RDF,RDFS,Updates},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\U89ZHHD4\\Halfeld-Ferrari et al. - 2017 - RDF Updates with Constraints.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\KT9SZGTE\\978-3-319-69548-8_16.html}
}

@inproceedings{hiotDOINGDEFTUtilisation2021,
  title = {{DOING@DEFT : utilisation de lexiques pour une classification efficace de cas cliniques}},
  shorttitle = {{DOING@ DEFT}},
  booktitle = {{Traitement Automatique des Langues Naturelles}},
  author = {Hiot, Nicolas and Minard, Anne-Lyse and Badin, Flora},
  editor = {Denis, Pascal and Grabar, Natalia and Fraisse, Amel and Cardon, R{\'e}mi and Jacquemin, Bernard and Kergosien, Eric and Balvet, Antonio},
  year = {2021},
  pages = {41--53},
  publisher = {{ATALA}},
  address = {{Lille, France}},
  abstract = {Nous pr\'esentons dans cet article notre participation \`a la t\^ache 1 de la campagne d'\'evaluation francophone DEFT 2021, sur l'identification du profil clinique du patient. Nous proposons une m\'ethode \'evolutive et efficace en temps et en ressources pour la classification de documents m\'edicaux pouvant \^etre facilement adapt\'ee \`a d'autres domaines de recherche. Notre syst\`eme a obtenu les meilleures performances sur cette t\^ache avec une F-mesure de 0,814.},
  copyright = {All rights reserved},
  hal_id = {hal-03265924},
  hal_version = {v1},
  langid = {french},
  pdf = {https://hal.archives-ouvertes.fr/hal-03265924/file/75.pdf},
  keywords = {â›” No DOI found,cas clinique,classification.,lexique,me,transducteur fini},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\F3TVPRP8\\Hiot et al. - 2021 - DOING@DEFT  utilisation de lexiques pour une clas.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\FHMF4CQI\\hal-03265924.html}
}

@misc{hiotUpdateChase2023,
  title = {{{UpdateChase}}},
  author = {Hiot, Nicolas and {Moret-Bailly}, Lucas and Chabin, Jacques},
  year = {2023},
  month = jan,
  urldate = {2023-07-21},
  abstract = {Impl\'ementation et benchmarks des algorithmes incr\'ementaux pour la mise \`a jour coh\'erente d'une base de donn\'ees graphe},
  keywords = {me},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\WPJMI7RA\\UpdateChase.html}
}

@article{imielinskiIncompleteInformationRelational1984,
  ids = {imielinskiIncompleteInformationRelational1984a},
  title = {Incomplete Information in Relational Databases},
  author = {Imielinski, Tomasz and Lipski Jr., Witold},
  year = {1984},
  month = sep,
  journal = {Journal of the ACM (JACM)},
  volume = {31},
  number = {4},
  pages = {761--791},
  publisher = {{ACM New York, NY, USA}},
  issn = {0004-5411},
  doi = {10.1145/1634.1886},
  keywords = {\#nosource},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\3MBFN4IU\\Imielinski et Lipski Jr. - 1984 - Incomplete information in relational databases.pdf}
}

@inproceedings{libkinIncompleteDataWhat2014,
  ids = {libkinIncompleteDataWhat2014a},
  title = {Incomplete Data: What Went Wrong, and How to Fix It},
  shorttitle = {Incomplete Data},
  booktitle = {Proceedings of the 33rd {{ACM SIGMOD-SIGACT-SIGART}} Symposium on {{Principles}} of Database Systems},
  author = {Libkin, Leonid},
  year = {2014},
  month = jun,
  series = {{{PODS}} '14},
  pages = {1--13},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2594538.2594561},
  urldate = {2023-08-03},
  abstract = {Incomplete data is ubiquitous: the more data we accumulate and the more widespread tools for integrating and exchanging data become, the more instances of incompleteness we have. And yet the subject is poorly handled by both practice and theory. Many queries for which students get full marks in their undergraduate courses will not work correctly in the presence of incomplete data, but these ways of evaluating queries are cast in stone -- SQL standard. We have many theoretical results on handling incomplete data but they are, by and large, about showing high complexity bounds, and thus are often dismissed by practitioners. Even worse, we have a basic theoretical notion of what it means to answer queries over incomplete data, and yet this is not at all what practical systems do. Is there a way out of this predicament? Can we have a theory of incompleteness that will appeal to theoreticians and practitioners alike, by explaining incompleteness and being at the same time implementable and useful for applications? After giving a critique of both the practice and the theory of handling incompleteness in databases, the paper outlines a possible way out of this crisis. The key idea is to combine three hitherto used approaches to incompleteness: one based on certain answers and representation systems, one based on viewing incomplete databases as logical theories, and one based on orderings expressing relative value of information.},
  isbn = {978-1-4503-2375-8},
  keywords = {incomplete information,query evaluation},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\RBSKIYBY\\Libkin - 2014 - Incomplete data what went wrong, and how to fix i.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\VN5CSSYT\\2594538.html}
}

@phdthesis{mahfoudhAdaptationOntologiesAvec2015,
  ids = {mahfoudhAdaptationOntologiesAvec2015a},
  title = {{Adaptation d'ontologies avec les grammaires de graphes typ\'es : \'evolution et fusion}},
  shorttitle = {{Adaptation d'ontologies avec les grammaires de graphes typ\'es}},
  author = {Mahfoudh, Mariem},
  year = {2015},
  month = may,
  urldate = {2019-03-07},
  abstract = {\'Etant une repr\'esentation formelle et explicite des connaissances d'un domaine, les ontologies font r\'eguli\`erement l'objet de nombreux changements et ont ainsi besoin d'\^etre constamment adapt\'ees pour notamment pouvoir \^etre r\'eutilis\'ees et r\'epondre aux nouveaux besoins. Leur r\'eutilisation peut prendre diff\'erentes formes (\'evolution, alignement, fusion, etc.), et pr\'esente plusieurs verrous scientifiques. L'un des plus importants est la pr\'eservation de la consistance de l'ontologie lors de son changement. Afin d'y r\'epondre, nous nous int\'eressons dans cette th\`ese \`a \'etudier les changements ontologiques et proposons un cadre formel capable de faire \'evoluer et de fusionner des ontologies sans affecter leur consistance. Premi\`erement, nous proposons TGGOnto (Typed Graph Grammars for Ontologies), un nouveau formalisme permettant la repr\'esentation des ontologies et leurs changements par les grammaires de graphes typ\'es. Un couplage entre ces deux formalismes est d\'efini afin de profiter des concepts des grammaires de graphes, notamment les NAC (Negative Application Conditions), pour la pr\'eservation de la consistance de l'ontologie adapt\'ee.Deuxi\`emement, nous proposons EvOGG (Evolving Ontologies with Graph Grammars), une approche d'\'evolution d'ontologies qui se base sur le formalisme GGTOnto et traite les inconsistances d'une mani\`ere a priori. Nous nous int\'eressons aux ontologies OWL et nous traitons \`a la fois : (1) l'enrichissement d'ontologies en \'etudiant leur niveau structurel et (2) le peuplement d'ontologies en \'etudiant les changements qui affectent les individus et leurs assertions. L'approche EvOGG d\'efinit des changements ontologiques de diff\'erents types (\'el\'ementaires, compos\'ees et complexes) et assure leur impl\'ementation par l'approche alg\'ebrique de transformation de graphes, SPO (Simple PushOut). Troisi\`emement, nous proposons GROM (Graph Rewriting for Ontology Merging), une approche de fusion d'ontologies capable d'\'eviter les redondances de donn\'ees et de diminuer les conflits dans le r\'esultat de fusion. L'approche propos\'ee se d\'ecompose en trois \'etapes : (1) la recherche de similarit\'e entre concepts en se basant sur des techniques syntaxiques, structurelles et s\'emantiques ; (2) la fusion d'ontologies par l'approche alg\'ebrique SPO ; (3) l'adaptation de l'ontologie globale r\'esultante par le biais des r\`egles de r\'e\'ecriture de graphes.Afin de valider les travaux men\'es dans cette th\`ese, nous avons d\'evelopp\'e plusieurs outils open source bas\'es sur l'outil AGG (Attributed Graph Grammar). Ces outils ont \'et\'e appliqu\'es sur un ensemble d'ontologies, essentiellement sur celles d\'evelopp\'ees dans le cadre du projet europ\'een CCAlps (Creatives Companies in Alpine Space) qui a financ\'e les travaux de cette th\`ese.},
  langid = {french},
  school = {Universit\'e de Haute Alsace-Mulhouse},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\58TKAI5X\\Mahfoudh - 2015 - Adaptation d'ontologies avec les grammaires de gra.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\ZHAL55QA\\tel-01528579.html}
}

@article{mahfoudhAlgebraicGraphTransformations2015,
  title = {Algebraic Graph Transformations for Formalizing Ontology Changes and Evolving Ontologies},
  author = {Mahfoudh, Mariem and Forestier, Germain and Thiry, Laurent and Hassenforder, Michel},
  year = {2015},
  journal = {Knowledge-Based Systems},
  volume = {73},
  pages = {212--226},
  issn = {0950-7051},
  doi = {10.1016/j.knosys.2014.10.007},
  keywords = {\#nosource,AGG,Algebraic graph transformations,Consistency,Ontology evolution,Typed Graph Grammars}
}

@inproceedings{maillotConsistencyEvaluationRDF2014,
  ids = {maillotConsistencyEvaluationRDF2014a,maillotConsistencyEvaluationRDF2014b},
  title = {Consistency {{Evaluation}} of {{RDF Data}}: {{How Data}} and {{Updates}} Are {{Relevant}}},
  shorttitle = {Consistency {{Evaluation}} of {{RDF Data}}},
  booktitle = {Tenth International Conference on Signal-Image Technology and Internet-Based Systems, {{SITIS}} 2014, Marrakech, Morocco, November 23-27, 2014},
  author = {Maillot, Pierre and Raimbault, Thomas and Genest, David and Loiseau, St{\'e}phane},
  year = {2014},
  month = nov,
  pages = {187--193},
  publisher = {{IEEE}},
  doi = {10.1109/SITIS.2014.39},
  abstract = {Trust and quality maintenance have always been problematic in the Semantic Web RDF bases. Numerous propositions to address these problems of data integration have been made, either based on ontologies or on additional metadata. However ontologies suffer from a adaptation speed slower than the data evolution speed and metadata requires ad-hoc manipulations of data by addition of extra-data. In this article we propose an original approach, based exclusively on data from the base, to evaluate the consistency of a candidate update to a RDF base, and finally to know if this update is relevant to the base. Our approach is inspired by case-based reasoning and uses similarity evaluation and query relaxation methods to compare a candidate update to the data from the base. If the modifications of a candidate update make the target part of the base more similar to other part (s) of the base, then this candidate update is considered consistent with the base and can be applied.},
  optbibsource = {dblp computer science bibliography, https://dblp.org},
  optbiburl = {https://dblp.org/rec/bib/conf/sitis/MaillotRGL14},
  optcrossref = {DBLP:conf/sitis/2014},
  optdoi = {10.1109/SITIS.2014.39},
  opttimestamp = {Wed, 16 Oct 2019 14:14:55 +0200},
  opturl = {https://doi.org/10.1109/SITIS.2014.39},
  keywords = {Case-based reasoning,Cognition,Consistency,Context,Data Integration,Databases,Ontologies,Ontology,Resource description framework,Semantic Web,Similarity,Weight measurement},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\SFABESXG\\Maillot et al. - 2014 - Consistency Evaluation of RDF Data How Data and U.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\7463EG8S\\7081546.html}
}

@inproceedings{minardDOINGDEFTCascade2020,
  title = {{DOING@DEFT : cascade de CRF pour l'annotation d'entit\'es cliniques imbriqu\'ees}},
  shorttitle = {{DOING@DEFT}},
  booktitle = {{6e conf\'erence conjointe Journ\'ees d'\'Etudes sur la Parole (JEP, 33e \'edition), Traitement Automatique des Langues Naturelles (TALN, 27e \'edition), Rencontre des \'Etudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R\'ECITAL, 22e \'edition). Atelier D\'Efi Fouille de Textes}},
  author = {Minard, Anne-Lyse and Roques, Andr{\'e}ane and Hiot, Nicolas and Halfeld Ferrari Alves, Mirian and Savary, Agata},
  editor = {Cardon, R{\'e}mi and Grabar, Natalia and Grouin, Cyril and Hamon, Thierry},
  year = {2020},
  pages = {66--78},
  publisher = {{ATALA; AFCP}},
  address = {{Nancy, France}},
  abstract = {Cet article pr\'esente le syst\`eme d\'evelopp\'e par l'\'equipe DOING pour la campagne d'\'evaluation DEFT 2020 portant sur la similarit\'e s\'emantique et l'extraction d'information fine. L'\'equipe a particip\'e uniquement \`a la t\^ache 3 : "extraction d'information". Nous avons utilis\'e une cascade de CRF pour annoter les diff\'erentes informations \`a rep\'erer. Nous nous sommes concentr\'es sur la question de l'imbrication des entit\'es et de la pertinence d'un type d'entit\'e pour apprendre \`a reconna\^itre un autre. Nous avons \'egalement test\'e l'utilisation d'une ressource externe, MedDRA, pour am\'eliorer les performances du syst\`eme et d'un pipeline plus complexe mais ne g\'erant pas l'imbrication des entit\'es. Nous avons soumis 3 runs et nous obtenons en moyenne sur toutes les classes des F-mesures de 0,64, 0,65 et 0,61.},
  copyright = {All rights reserved},
  hal_id = {hal-02784743},
  hal_version = {v3},
  langid = {french},
  pdf = {https://hal.archives-ouvertes.fr/hal-02784743v3/file/212.pdf},
  keywords = {â›” No DOI found,apprentissage automatique,cas cliniques,CRF.,entit\'es cliniques,entit\'es imbriqu\'ees,extraction d'information fine,me},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\8PM6XVUJ\\Minard et al. - 2020 - DOING@DEFT  cascade de CRF pour l'annotation d'en.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\DY6IJYRR\\hal-02784743.html}
}

@inproceedings{pokornyGraphDatabasesTheir2015,
  ids = {pokornyGraphDatabasesTheir2015a},
  title = {Graph {{Databases}}: {{Their Power}} and {{Limitations}}},
  shorttitle = {Graph {{Databases}}},
  booktitle = {Computer {{Information Systems}} and {{Industrial Management}}: 14th {{IFIP TC}} 8 {{International Conference}}, {{CISIM}} 2015, {{Warsaw}}, {{Poland}}, {{September}} 24-26, 2015, {{Proceedings}} 14},
  author = {Pokorn{\'y}, Jaroslav},
  editor = {Saeed, Khalid and Homenda, Wladyslaw},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {58--69},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-24369-6_5},
  abstract = {Real world data offers a lot of possibilities to be represented as graphs. As a result we obtain undirected or directed graphs, multigraphs and hypergraphs, labelled or weighted graphs and their variants. A development of graph modelling brings also new approaches, e.g., considering constraints. Processing graphs in a database way can be done in many different ways. Some graphs can be represented as JSON or XML structures and processed by their native database tools. More generally, a graph database is specified as any storage system that provides index-free adjacency, i.e. an explicit graph structure. Graph database technology contains some technological features inherent to traditional databases, e.g. ACID properties and availability. Use cases of graph databases like Neo4j, OrientDB, InfiniteGraph, FlockDB, AllegroGraph, and others, document that graph databases are becoming a common means for any connected data. In Big Data era, important questions are connected with scalability for large graphs as well as scaling for read/write operations. For example, scaling graph data by distributing it in a network is much more difficult than scaling simpler data models and is still a work in progress. Still a challenge is pattern matching in graphs providing, in principle, an arbitrarily complex identity function. Mining complete frequent patterns from graph databases is also challenging since supporting operations are computationally costly. In this paper, we discuss recent advances and limitations in these areas as well as future directions.},
  isbn = {978-3-319-24369-6},
  langid = {english},
  keywords = {Big graphs,Graph database,Graph querying,Graph scalability,Graph storage},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\4PLH92NN\\PokornÃ½ - 2015 - Graph Databases Their Power and Limitations.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\Z5XWGHCZ\\978-3-319-24369-6_5.html}
}

@inproceedings{raadDetectionLiensIdentite2017,
  title = {D\'etection de Liens d'identit\'e Contextuels Dans Une Base de Connaissances.},
  booktitle = {{{IC}} 2017 - 28es {{Journ\'ees}} Francophones d'{{Ing\'enierie}} Des {{Connaissances}}},
  author = {Raad, Joe and Pernelle, Nathalie and Sa{\"i}s, Fatiha},
  editor = {Roussey, Catherine},
  year = {2017},
  month = jul,
  series = {Actes {{IC}} 2017 28es {{Journ\'ees}} Francophones d'{{Ing\'enierie}} Des {{Connaissances}}},
  pages = {56--67},
  address = {{Caen, France}},
  urldate = {2019-03-04},
  abstract = {De nombreuses applications du Web de donn\'ees exploitent des liens d'identit\'es d\'eclar\'es \`a l'aide du constructeur owl :sameAs. Cependant, diff\'erentes \'etudes ont montr\'e qu'une utilisation abusive de ces liens peut conduire \`a des inf\'erences erron\'ees ou contradictoires. Dans ce papier nous proposons de calculer des liens d'identit\'es contextuels qui permettent d'expliciter les contextes dans lesquels ces liens sont valides. La notion de contexte que nous proposons est repr\'esent\'ee en se basant sur l'ontologie de domaine dans laquelle les instances sont repr\'esent\'ees. Nous avons exp\'eriment\'e cette approche dans le domaine des donn\'ees scientifiques o\`u les \'el\'ements d\'ecrivant les exp\'eriences partagent rarement un lien d'identit\'e tel que d\'efini par owl :sameAs.},
  keywords = {Bases de connaissances,Contextes,Enrichissement,Liage de donn\'ees,Ontologies},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\2TW56Q92\\Raad et al. - 2017 - DÃ©tection de liens d'identitÃ© contextuels dans une.pdf}
}

@article{reiterSoundSometimesComplete1986,
  ids = {reiterSoundSometimesComplete1986a},
  title = {A Sound and Sometimes Complete Query Evaluation Algorithm for Relational Databases with Null Values},
  author = {Reiter, Raymond},
  year = {1986},
  month = apr,
  journal = {Journal of the ACM (JACM)},
  volume = {33},
  number = {2},
  pages = {349--370},
  publisher = {{ACM New York, NY, USA}},
  issn = {0004-5411},
  doi = {10.1145/5383.5388},
  abstract = {A sound and, in certain cases, complete method is described for evaluating queries in relational databases with null values where these nulls represent existing but unknown individuals. The soundness and completeness results are proved relative to a formalization of such databases as suitable theories of first-order logic. Because the algorithm conforms to the relational algebra, it may easily be incorporated into existing relational systems.},
  keywords = {\#nosource},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\5I5LMVN4\\Reiter - 1986 - A sound and sometimes complete query evaluation al.pdf;C\:\\Users\\nhiot\\Zotero\\storage\\J9PHZZNY\\5383.html}
}

@inproceedings{savaryRelationExtractionClinical2022,
  title = {Relation Extraction from Clinical Cases for a Knowledge Graph},
  booktitle = {European {{Conference}} on {{Advances}} in {{Databases}} and {{Information Systems}}},
  author = {Savary, Agata and Silvanovich, Alena and Minard, Anne-Lyse and Hiot, Nicolas and Halfeld Ferrari, Mirian},
  year = {2022},
  pages = {353--365},
  publisher = {{Springer}},
  keywords = {\#nosource,â›” No DOI found,me}
}

@article{scheweLimitationsRuleTriggering1998,
  ids = {ScT98},
  title = {Limitations of Rule Triggering Systems for Integrity Maintenance in the Context of Transition Specifications},
  author = {Schewe, Klaus-Dieter and Thalheim, Bernhard},
  year = {1998},
  journal = {Acta Cybernetica},
  volume = {13},
  number = {3},
  pages = {277--304},
  publisher = {{University of Szeged}},
  optbibsource = {dblp computer science bibliography, https://dblp.org},
  optbiburl = {https://dblp.org/rec/bib/journals/actaC/ScheweT98},
  opttimestamp = {Tue, 09 Jul 2013 18:10:34 +0200},
  opturl = {http://www.inf.u-szeged.hu/actacybernetica/edb/vol13n3/Schewe{$_1$}998\textsubscript{A}ctaCybernetica.xml},
  keywords = {\#nosource,â›” No DOI found},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\YW5ZUGF8\\Schewe et Thalheim - 1998 - Limitations of rule triggering systems for integri.pdf}
}

@phdthesis{sirangeloRepresentingQueryingIncomplete2014,
  ids = {sirangeloRepresentingQueryingIncomplete2014a},
  title = {Representing and {{Querying Incomplete Information}}: A {{Data Interoperability Perspective}}},
  shorttitle = {Representing and {{Querying Incomplete Information}}},
  author = {Sirangelo, Cristina},
  year = {2014},
  optbibsource = {dblp computer science bibliography, https://dblp.org},
  optbiburl = {https://dblp.org/rec/books/hal/Sirangelo14.bib},
  opttimestamp = {Sat, 30 Sep 2017 21:10:29 +0200},
  school = {Ecole Normale Sup\'erieure de Cachan},
  keywords = {\#nosource},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\QL9267EA\\Sirangelo - 2014 - Representing and Querying Incomplete Information .pdf}
}

@article{winslettModelbasedApproachUpdating1988,
  title = {A Model-Based Approach to Updating Databases with Incomplete Information},
  author = {Winslett, Marianne},
  year = {1988},
  month = jun,
  journal = {ACM Transactions on Database Systems (TODS)},
  volume = {13},
  number = {2},
  pages = {167--196},
  publisher = {{ACM New York, NY, USA}},
  issn = {0362-5915},
  doi = {10.1145/42338.42386},
  urldate = {2023-08-03},
  abstract = {Suppose one wishes to construct, use, and maintain a database of facts about the real world, even though the state of that world is only partially known. In the artificial intelligence domain, this problem arises when an agent has a base set of beliefs that reflect partial knowledge about the world, and then tries to incorporate new, possibly contradictory knowledge into this set of beliefs. In the database domain, one facet of this situation is the well-known null values problem. We choose to represent such a database as a logical theory, and view the models of the theory as representing possible states of the world that are consistent with all known information. How can new information be incorporated into the database? For example, given the new information that ``b or c is true,'' how can one get rid of all outdated information about b and c, add the new information, and yet in the process not disturb any other information in the database? In current-day database management systems, the difficult and tedious burden of determining exactly what to add and remove from the database is placed on the user. The goal of our research was to relieve users of that burden, by equipping the database management system with update algorithms that can automatically determine what to add and remove from the database. Under our approach, new information about the state of the world is input to the database management system as a well-formed formula that the state of the world is now known to satisfy. We have constructed database update algorithms to interpret this update formula and incorporate the new information represented by the formula into the database without further assistance from the user. In this paper we show how to embed the incomplete database and the incoming information in the language of mathematical logic, explain the semantics of our update operators, and discuss the algorithms that implement these operators.},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\JHFT95PM\\Winslett - 1988 - A model-based approach to updating databases with .pdf;C\:\\Users\\nhiot\\Zotero\\storage\\IP27ELLK\\42338.html}
}

@book{winslettUpdatingLogicalDatabases2004,
  ids = {UpdatingLogicalDatabases},
  title = {Updating {{Logical Databases}} ({{Cambridge Tracts}} in {{Theoretical Computer Science}})},
  author = {Winslett, Marianne},
  year = {2004},
  publisher = {{Cambridge University Press}},
  doi = {10.5555/1207643},
  langid = {english},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\R49IGIG4\\1207643.html}
}

@inproceedings{zanioloDatabaseRelationsNull1982,
  title = {Database Relations with Null Values},
  booktitle = {Proceedings of the 1st {{ACM SIGACT-SIGMOD}} Symposium on {{Principles}} of Database Systems},
  author = {Zaniolo, Carlo},
  year = {1982},
  pages = {27--33},
  keywords = {â›” No DOI found},
  file = {C\:\\Users\\nhiot\\Zotero\\storage\\H9GM6357\\Zaniolo - 1982 - Database relations with null values.pdf}
}
